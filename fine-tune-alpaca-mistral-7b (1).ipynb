{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -U transformers \n!pip install -U datasets \n!pip install -U accelerate \n!pip install -U peft \n!pip install -U trl \n!pip install -U bitsandbytes \n!pip install -U wandb\n!pip install -U unsloth\n!pip install -U torch==2.3.0\n# !pip install xformers==0.0.27\n#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T06:28:38.825361Z","iopub.execute_input":"2024-11-29T06:28:38.825653Z","iopub.status.idle":"2024-11-29T06:34:24.723484Z","shell.execute_reply.started":"2024-11-29T06:28:38.825625Z","shell.execute_reply":"2024-11-29T06:34:24.722472Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip uninstall torchvision torchaudio -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T06:54:12.737491Z","iopub.execute_input":"2024-11-29T06:54:12.738400Z","iopub.status.idle":"2024-11-29T06:54:14.938000Z","shell.execute_reply.started":"2024-11-29T06:54:12.738358Z","shell.execute_reply":"2024-11-29T06:54:14.936855Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: torchvision 0.19.0\nUninstalling torchvision-0.19.0:\n  Successfully uninstalled torchvision-0.19.0\nFound existing installation: torchaudio 2.4.0\nUninstalling torchaudio-2.4.0:\n  Successfully uninstalled torchaudio-2.4.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install xformers==0.0.27","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T06:54:19.423294Z","iopub.execute_input":"2024-11-29T06:54:19.423650Z","iopub.status.idle":"2024-11-29T06:55:18.704416Z","shell.execute_reply.started":"2024-11-29T06:54:19.423615Z","shell.execute_reply":"2024-11-29T06:55:18.703401Z"}},"outputs":[{"name":"stdout","text":"Collecting xformers==0.0.27\n  Downloading xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from xformers==0.0.27) (1.26.4)\nCollecting torch==2.3.1 (from xformers==0.0.27)\n  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (1.13.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1->xformers==0.0.27) (12.1.105)\nCollecting triton==2.3.1 (from torch==2.3.1->xformers==0.0.27)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->xformers==0.0.27) (12.4.127)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.1->xformers==0.0.27) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.1->xformers==0.0.27) (1.3.0)\nDownloading xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl (164.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.1/164.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, torch, xformers\n  Attempting uninstall: triton\n    Found existing installation: triton 2.3.0\n    Uninstalling triton-2.3.0:\n      Successfully uninstalled triton-2.3.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.3.0\n    Uninstalling torch-2.3.0:\n      Successfully uninstalled torch-2.3.0\n  Attempting uninstall: xformers\n    Found existing installation: xformers 0.0.28.post3\n    Uninstalling xformers-0.0.28.post3:\n      Successfully uninstalled xformers-0.0.28.post3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nfastai 2.7.17 requires torchvision>=0.11, which is not installed.\ntimm 1.0.9 requires torchvision, which is not installed.\nunsloth 2024.11.11 requires torch>=2.4.0, but you have torch 2.3.1 which is incompatible.\nunsloth 2024.11.11 requires triton>=3.0.0, but you have triton 2.3.1 which is incompatible.\nunsloth 2024.11.11 requires xformers>=0.0.27.post2, but you have xformers 0.0.27 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.3.1 triton-2.3.1 xformers-0.0.27\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n\n# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\nfourbit_models = [\n    \"unsloth/mistral-7b-bnb-4bit\",\n    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n    \"unsloth/llama-2-7b-bnb-4bit\",\n    \"unsloth/llama-2-13b-bnb-4bit\",\n    \"unsloth/codellama-34b-bnb-4bit\",\n    \"unsloth/tinyllama-bnb-4bit\",\n    \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n    \"unsloth/gemma-2b-bnb-4bit\",\n] # More models at https://huggingface.co/unsloth\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/mistral-7b-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T06:58:49.491237Z","iopub.execute_input":"2024-11-29T06:58:49.491989Z","iopub.status.idle":"2024-11-29T06:59:31.296510Z","shell.execute_reply.started":"2024-11-29T06:58:49.491951Z","shell.execute_reply":"2024-11-29T06:59:31.295643Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2024.11.11: Fast Mistral patching. Transformers:4.46.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.3.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 2.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.27. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.13G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5ca52ef8a634663a6656b33d1f9d35d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/155 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36c15d93d55b4645908cbf212ed5e841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a29d4ad8b5d4f3aac93a32abe510713"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f054144133f94595a1e7d2b554fce282"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3979ea453e75480c80a1ed4b8e5f0d66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45bc688cbf654f50905dd550b297f2ac"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T07:04:36.718177Z","iopub.execute_input":"2024-11-29T07:04:36.718549Z","iopub.status.idle":"2024-11-29T07:04:41.685721Z","shell.execute_reply.started":"2024-11-29T07:04:36.718502Z","shell.execute_reply":"2024-11-29T07:04:41.684968Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2024.11.11 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"\n\n\nEOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"vivekdugale/latest_eng_sentiment_dataset_alpaca_format\", split = \"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T07:05:45.975861Z","iopub.execute_input":"2024-11-29T07:05:45.976230Z","iopub.status.idle":"2024-11-29T07:05:48.172804Z","shell.execute_reply.started":"2024-11-29T07:05:45.976198Z","shell.execute_reply":"2024-11-29T07:05:48.171912Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"(â€¦)_eng_sentiment_dataset_alpaca_format.csv:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6626797a3f6e4cf591cdc7475de89b0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1869 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da66faef0c54fb992f7b09a78027f37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1869 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e1c60ce0e94b028d40336a0b87dbdf"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        num_train_epochs = 1, # Set num_train_epochs = 1 for full training runs\n        #max_steps = 20, # Set num_train_epochs = 1 for full training runs\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"cosine\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        gradient_checkpointing=True\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T07:06:06.721435Z","iopub.execute_input":"2024-11-29T07:06:06.722147Z","iopub.status.idle":"2024-11-29T07:06:14.000814Z","shell.execute_reply.started":"2024-11-29T07:06:06.722105Z","shell.execute_reply":"2024-11-29T07:06:14.000082Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/1869 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5722efe6a834459d9da5fe3d45e1beea"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T07:06:15.301650Z","iopub.execute_input":"2024-11-29T07:06:15.302084Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 1,869 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 233\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241129_070650-0a4vnl8w</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jaivilatkar-jarvis-invest/huggingface/runs/0a4vnl8w' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/jaivilatkar-jarvis-invest/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jaivilatkar-jarvis-invest/huggingface' target=\"_blank\">https://wandb.ai/jaivilatkar-jarvis-invest/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jaivilatkar-jarvis-invest/huggingface/runs/0a4vnl8w' target=\"_blank\">https://wandb.ai/jaivilatkar-jarvis-invest/huggingface/runs/0a4vnl8w</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='19' max='233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 19/233 13:40 < 2:52:09, 0.02 it/s, Epoch 0.08/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.307400</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.294700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.289300</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.259700</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.127100</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.008700</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.822300</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.884400</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.541400</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.650500</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.525500</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.609400</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.563700</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.524500</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.588300</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.722300</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.501100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"instruction = \"\"\"\n            You are an expert in Named Entity Recognition and Financial Analysis, specializing\n            in extracting stock, sector, industry entities from news content and analyzing their sentiment.\n            Your task is to process content in both English and Arabic, providing insights exclusively in English.\n\n            ## Core Responsibilities:\n            1. Identify ALL unique stocks (including companies/organizations), sectors & industries mentioned in the provided news content.\n            2. Determine the sentiment for each identified entity based solely on the provided content.\n            3. Translate any Arabic entity names to their English equivalents.\n            4. Provide a comprehensive JSON-formatted response for each and every identified entity.\n\n            ## Output Format:\n            For each unique stock, sector & industry mentioned, provide a JSON object with the following structure:\n\n            \"entity_type\": \"stock or sector or industry\",\n            \"entity_name\": \"Name of the identified entity\",\n            \"sentiment_score\": 0.0000,\n            \"sentiment_class\": \"Sentiment Category\",\n            \"rationale\": \"Justification for the sentiment (2-3 lines)\"\n\n            ## Key Details:\n\n            1. entity_type:\n            - Always in English, regardless of input language.\n            - Must be either 'stock', 'sector', or 'industry'.\n            - Use the most common or official English name for the entity.\n\n            2. entity_name:\n            - Always in English, regardless of input language.\n\n            3. sentiment_score:\n            - A float between 0 and 1, to four decimal places.\n            - 0 represents extremely negative, 1 represents extremely positive.\n\n            4. sentiment_class:\n            - Categorize based on the sentiment_score:\n                * 'Positive': 0.8000 to 1.0000\n                * 'Slightly Positive': 0.6000 to 0.7999\n                * 'Neutral': 0.4000 to 0.5999\n                * 'Slightly Negative': 0.2000 to 0.3999\n                * 'Negative': 0.0000 to 0.1999\n\n            5. rationale:\n            - Provide a 2-3 line justification for the sentiment.\n            - Base this strictly on information from the provided news content.\n            - Focus only on factors relevant to the specific stock/company, sector, or industry.\n\n\n            ## Analysis Instructions:\n            1. Thoroughly analyze the provided news content:\n            2. Identify ALL unique stocks, sectors, and industries mentioned, no matter how brief the mention.\n            3. For each entity, determine the sentiment based solely on the provided content.\n            4. Translate any Arabic entity names to their English equivalents.\n            5. Ensure all output, including entity_type, entity_name, and rationales, is in English.\n            6. Provide one JSON object per unique entity, avoiding duplicates.\n            7. Assign varied sentiment scores based on the specific context for each entity.\n\n\n            - DO NOT invent or assume information not present in the news content i.e.\n            - Maintain consistency between sentiment_score and sentiment_class.\n            - Ensure entity_names are accurate and widely recognized English versions.\n            - If the news is in Arabic, accurately translate relevant information to English.\n            - Do not create additional fields beyond those specified.\n            - Adhere strictly to the JSON format and field names provided.\n            - Sentiment scores should be precise (up to 4 decimal places) and can be any value between 0 and 1.\n            - Assign sentiment scores and classes based on the actual sentiment in the news, which may vary for different entities in the same article.\n\n            ## Self-Check Before Submission:\n            2. Have I provided a separate JSON object for each unique entity?\n            3. Are all entity names in English and accurately represented?\n            4. Have I based my sentiment analysis solely on the provided content?\n            5. Are my sentiment scores and classes consistent and justified?\n            6. Have I provided a rationale for each sentiment analysis?\n\n            ## Example Output:\n\n                \"entity_type\": \"stock\",\n                \"entity_name\": \"ICICI Bank\",\n                \"sentiment_class\": \"Positive\",\n                \"sentiment_score\": 0.8956,\n                \"rationale\": \"ICICI Bank emerged as one of the biggest winners last week, with its valuation surging by Rs 63,359.79 crore. This significant increase in valuation indicates strong market confidence and positive investor sentiment towards the bank.\"\n\n\n            Remember, your analysis should be thorough, accurate, and strictly based on the content provided. Avoid speculation or inclusion of external knowledge not present in the news article. Ensure that ALL mentioned entities are captured, analyzed, and properly mapped to the provided lists.\n\n            ### Input:\n            {}\n\n            ### Response:\n            {}\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:09:07.689201Z","iopub.execute_input":"2024-11-28T12:09:07.690013Z","iopub.status.idle":"2024-11-28T12:09:07.697302Z","shell.execute_reply.started":"2024-11-28T12:09:07.689975Z","shell.execute_reply":"2024-11-28T12:09:07.696415Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"text=\"\"\"The Capital Market Authority announces that it has issued its resolution approving AlBilad Investment CompanyÃ¢â‚¬â„¢s request to offer \" Albilad CSOP MSCI Hong Kong China Equity ETF \" units on the Saudi Stock Exchange (Tadawul) as an Exchange Traded Fund. Terms and Conditions (T&Cs) of \" Albilad CSOP MSCI Hong Kong China Equity ETF \" can be obtained from the fund managerÃ¢â‚¬â„¢s website and the CMA's website, which contain all relevant information that the investor needs to consider before making (or refraining from) an investment decision. An investment decision without reading the T&Cs carefully or fully reviewing its content may involve high risk. Therefore, investors should carefully read the T&Cs, which include detailed information on the \" Albilad CSOP MSCI Hong Kong China Equity ETF \" strategy, objectives and risk factors. Thus, providing potential investors the ability to evaluate the viability of investing in \" Albilad CSOP MSCI Hong Kong China Equity ETF \", taking into consideration the associated risks. And if the T&Cs prove to be difficult to understand, it is recommended to consult an authorized financial advisor. The CMAÃ¢â‚¬â„¢s approval of \"Albilad CSOP MSCI Hong Kong China Equity ETF \" should not be considered as a recommendation to invest in it. The CMA's approval of \"Albilad CSOP MSCI Hong Kong China Equity ETF\" merely means that the legal requirements as per the Capital Market Law and its Implementing Regulations have been met.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:12:13.320531Z","iopub.execute_input":"2024-11-28T12:12:13.321414Z","iopub.status.idle":"2024-11-28T12:12:13.326948Z","shell.execute_reply.started":"2024-11-28T12:12:13.321378Z","shell.execute_reply":"2024-11-28T12:12:13.326067Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"text=\"\"\"Saudi Exchange announces the listing and trading shares of Ã¢â‚¬Å“United Arab Float Glass Co.Ã¢â‚¬â€Œ on Nomu Ã¢â‚¬â€œ Parallel Market on Wednesday 18/09/2024, as a direct listing with the symbol 9611 and ISIN Code SA164G54M5H6 with +/- 30% daily price fluctuation limits and +/- 10% static price fluctuation limits. As the company is planning to meet the liquidity requirements with a liquidity provider*. For more information about Ã¢â‚¬Å“United Arab Float Glass Co.Ã¢â‚¬â€Œ, please (click here) to review the registration document. And for more information on Nomu Ã¢â‚¬â€œ Parallel Market, please visit the Knowledge Center page on our website by (clicking here). *For more details about liquidity requirements, please click here\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:17:30.783396Z","iopub.execute_input":"2024-11-28T12:17:30.783769Z","iopub.status.idle":"2024-11-28T12:17:30.789159Z","shell.execute_reply.started":"2024-11-28T12:17:30.783739Z","shell.execute_reply":"2024-11-28T12:17:30.788413Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"text=\"\"\"The Capital Market Authority \"CMA\" Board has issued its resolution dated on 15/03/1446H corresponding to 18/09/2024G approving of Al Battal Factory for Chemical Industries Company \"the Company\" application for the registration and offering of (670,000) shares representing (20.09%) of the Company's share capital in the Parallel Market. The offer will be confined to Qualified Investors stipulated in the Glossary of Defined Terms Used in the Regulations and Rules of the Capital Market Authority. The prospectus will be published within sufficient time prior to the start of the offering.\nProspective Qualified Investors should conduct their own due diligence on the information disclosed in the prospectus. If the prospectus proves difficult to understand, it is recommended to consult with an authorized financial advisor prior to making any investment decision.\nThe CMAâ€™s approval on the application should never be considered as a recommendation to invest in the offering or shares of the company. The CMAâ€™s approval on the application merely means that the legal requirements as per the Capital Market Law and its Implementing Regulations have been met.\nThe CMAâ€™s approval on the application shall be valid for (6) months from the CMA Board resolution date. The approval shall be deemed cancelled if the offering and listing of the Company's shares are not completed within this period.\n \"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:20:08.807845Z","iopub.execute_input":"2024-11-26T06:20:08.808191Z","iopub.status.idle":"2024-11-26T06:20:08.814277Z","shell.execute_reply.started":"2024-11-26T06:20:08.808163Z","shell.execute_reply":"2024-11-26T06:20:08.813291Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# alpaca_prompt = Copied from above\nFastLanguageModel.for_inference(model) # Enable native 2x faster inference\ninputs = tokenizer(\n[\n    alpaca_prompt.format(\n        instruction, # instruction\n        text, # input\n        \"\", # output - leave this blank for generation!\n    )\n], return_tensors = \"pt\").to(\"cuda\")\n\noutputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\ntokenizer.batch_decode(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T12:17:33.258843Z","iopub.execute_input":"2024-11-28T12:17:33.259196Z","iopub.status.idle":"2024-11-28T12:17:38.812705Z","shell.execute_reply.started":"2024-11-28T12:17:33.259163Z","shell.execute_reply":"2024-11-28T12:17:38.811835Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n\\n            You are an expert in Named Entity Recognition and Financial Analysis, specializing\\n            in extracting stock, sector, industry entities from news content and analyzing their sentiment.\\n            Your task is to process content in both English and Arabic, providing insights exclusively in English.\\n\\n            ## Core Responsibilities:\\n            1. Identify ALL unique stocks (including companies/organizations), sectors & industries mentioned in the provided news content.\\n            2. Determine the sentiment for each identified entity based solely on the provided content.\\n            3. Translate any Arabic entity names to their English equivalents.\\n            4. Provide a comprehensive JSON-formatted response for each and every identified entity.\\n\\n            ## Output Format:\\n            For each unique stock, sector & industry mentioned, provide a JSON object with the following structure:\\n\\n            \"entity_type\": \"stock or sector or industry\",\\n            \"entity_name\": \"Name of the identified entity\",\\n            \"sentiment_score\": 0.0000,\\n            \"sentiment_class\": \"Sentiment Category\",\\n            \"rationale\": \"Justification for the sentiment (2-3 lines)\"\\n\\n            ## Key Details:\\n\\n            1. entity_type:\\n            - Always in English, regardless of input language.\\n            - Must be either \\'stock\\', \\'sector\\', or \\'industry\\'.\\n            - Use the most common or official English name for the entity.\\n\\n            2. entity_name:\\n            - Always in English, regardless of input language.\\n\\n            3. sentiment_score:\\n            - A float between 0 and 1, to four decimal places.\\n            - 0 represents extremely negative, 1 represents extremely positive.\\n\\n            4. sentiment_class:\\n            - Categorize based on the sentiment_score:\\n                * \\'Positive\\': 0.8000 to 1.0000\\n                * \\'Slightly Positive\\': 0.6000 to 0.7999\\n                * \\'Neutral\\': 0.4000 to 0.5999\\n                * \\'Slightly Negative\\': 0.2000 to 0.3999\\n                * \\'Negative\\': 0.0000 to 0.1999\\n\\n            5. rationale:\\n            - Provide a 2-3 line justification for the sentiment.\\n            - Base this strictly on information from the provided news content.\\n            - Focus only on factors relevant to the specific stock/company, sector, or industry.\\n\\n\\n            ## Analysis Instructions:\\n            1. Thoroughly analyze the provided news content:\\n            2. Identify ALL unique stocks, sectors, and industries mentioned, no matter how brief the mention.\\n            3. For each entity, determine the sentiment based solely on the provided content.\\n            4. Translate any Arabic entity names to their English equivalents.\\n            5. Ensure all output, including entity_type, entity_name, and rationales, is in English.\\n            6. Provide one JSON object per unique entity, avoiding duplicates.\\n            7. Assign varied sentiment scores based on the specific context for each entity.\\n\\n\\n            - DO NOT invent or assume information not present in the news content i.e.\\n            - Maintain consistency between sentiment_score and sentiment_class.\\n            - Ensure entity_names are accurate and widely recognized English versions.\\n            - If the news is in Arabic, accurately translate relevant information to English.\\n            - Do not create additional fields beyond those specified.\\n            - Adhere strictly to the JSON format and field names provided.\\n            - Sentiment scores should be precise (up to 4 decimal places) and can be any value between 0 and 1.\\n            - Assign sentiment scores and classes based on the actual sentiment in the news, which may vary for different entities in the same article.\\n\\n            ## Self-Check Before Submission:\\n            2. Have I provided a separate JSON object for each unique entity?\\n            3. Are all entity names in English and accurately represented?\\n            4. Have I based my sentiment analysis solely on the provided content?\\n            5. Are my sentiment scores and classes consistent and justified?\\n            6. Have I provided a rationale for each sentiment analysis?\\n\\n            ## Example Output:\\n\\n                \"entity_type\": \"stock\",\\n                \"entity_name\": \"ICICI Bank\",\\n                \"sentiment_class\": \"Positive\",\\n                \"sentiment_score\": 0.8956,\\n                \"rationale\": \"ICICI Bank emerged as one of the biggest winners last week, with its valuation surging by Rs 63,359.79 crore. This significant increase in valuation indicates strong market confidence and positive investor sentiment towards the bank.\"\\n\\n\\n            Remember, your analysis should be thorough, accurate, and strictly based on the content provided. Avoid speculation or inclusion of external knowledge not present in the news article. Ensure that ALL mentioned entities are captured, analyzed, and properly mapped to the provided lists.\\n\\n            ### Input:\\n            {}\\n\\n            ### Response:\\n            {}\\n\\n### Input:\\nSaudi Exchange announces the listing and trading shares of Ã¢â‚¬Å“United Arab Float Glass Co.Ã¢â‚¬\\u200c on Nomu Ã¢â‚¬â€œ Parallel Market on Wednesday 18/09/2024, as a direct listing with the symbol 9611 and ISIN Code SA164G54M5H6 with +/- 30% daily price fluctuation limits and +/- 10% static price fluctuation limits. As the company is planning to meet the liquidity requirements with a liquidity provider*. For more information about Ã¢â‚¬Å“United Arab Float Glass Co.Ã¢â‚¬\\u200c, please (click here) to review the registration document. And for more information on Nomu Ã¢â‚¬â€œ Parallel Market, please visit the Knowledge Center page on our website by (clicking here). *For more details about liquidity requirements, please click here\\n\\n### Response:\\n[{\\'entity_type\\': \\'stock\\', \\'entity_name\\': \\'United Arab Float Glass Co.\\', \\'sentiment_class\\': \\'positive\\', \\'sentiment_score\\': 0.5, \\'rationale\\': \"The company\\'s listing on the Saudi Exchange\\'s Nomu - Parallel']"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\n# hf_token = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nlogin(token = \"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:20:53.556539Z","iopub.execute_input":"2024-11-26T06:20:53.557321Z","iopub.status.idle":"2024-11-26T06:20:53.642983Z","shell.execute_reply.started":"2024-11-26T06:20:53.557288Z","shell.execute_reply":"2024-11-26T06:20:53.641850Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"new_model =\"test_model\" #\"mistral_7b_sentiment_analysis_eng\"\ntrainer.model.save_pretrained(new_model)\ntrainer.model.push_to_hub(new_model, use_temp_dir=False)\ntokenizer.push_to_hub(new_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T06:21:28.684038Z","iopub.execute_input":"2024-11-26T06:21:28.684416Z","iopub.status.idle":"2024-11-26T06:21:35.652392Z","shell.execute_reply.started":"2024-11-26T06:21:28.684384Z","shell.execute_reply":"2024-11-26T06:21:35.651428Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/582 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"386bdd1ae45843c78a231f17cd073f11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6909b25d253d43b18375c7d5dfae6c52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7047bbb269794388acf7e958c863b65b"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/test_model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a24a19161f23450998378af4df2e96f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e94d6c3e2d234562a7054a791904f51f"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"trainer.push_to_hub(new_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T12:59:14.036270Z","iopub.execute_input":"2024-11-25T12:59:14.037199Z","iopub.status.idle":"2024-11-25T12:59:20.071925Z","shell.execute_reply.started":"2024-11-25T12:59:14.037148Z","shell.execute_reply":"2024-11-25T12:59:20.071076Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b3a7aefdce4b69a3f36b2c7ff3a1b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb27d6857b634d4a8928838b96f9e076"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(â€¦)ut.tfevents.1732536002.af6559144b69.30.0:   0%|          | 0.00/18.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d573b94c0d145a593e9a80674439bc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b065d7029ea4a1f968b5f42288d4bac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.50k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033871a820c943f48289582592b6fc72"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/vivekdugale/outputs/commit/6b5141fb9dbf0a03d0e8e205e5230771ec37f402', commit_message='mistral_7b_sentiment_analysis_eng', commit_description='', oid='6b5141fb9dbf0a03d0e8e205e5230771ec37f402', pr_url=None, repo_url=RepoUrl('https://huggingface.co/vivekdugale/outputs', endpoint='https://huggingface.co', repo_type='model', repo_id='vivekdugale/outputs'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}